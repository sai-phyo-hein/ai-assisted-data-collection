{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12588364,"sourceType":"datasetVersion","datasetId":7805339}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-26T18:26:59.075520Z","iopub.execute_input":"2025-07-26T18:26:59.075841Z","iopub.status.idle":"2025-07-26T18:26:59.300871Z","shell.execute_reply.started":"2025-07-26T18:26:59.075818Z","shell.execute_reply":"2025-07-26T18:26:59.300158Z"}},"outputs":[{"name":"stdout","text":"Sat Jul 26 18:26:59 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   37C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   39C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install edgartools -qq\n!pip install ollama -qq ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T18:26:59.302526Z","iopub.execute_input":"2025-07-26T18:26:59.302782Z","iopub.status.idle":"2025-07-26T18:27:11.937621Z","shell.execute_reply.started":"2025-07-26T18:26:59.302757Z","shell.execute_reply":"2025-07-26T18:27:11.936614Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nfrom edgar import *\nfrom datetime import datetime, date\nset_identity('mgsai.1121@gmail.com')\nimport subprocess\nimport ollama","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T18:27:11.938842Z","iopub.execute_input":"2025-07-26T18:27:11.939176Z","iopub.status.idle":"2025-07-26T18:27:14.292512Z","shell.execute_reply.started":"2025-07-26T18:27:11.939135Z","shell.execute_reply":"2025-07-26T18:27:14.291771Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!sudo apt update > /dev/null 2>&1\n!sudo apt install pciutils lshw > /dev/null 2>&1\n!curl -fsSL https://ollama.com/install.sh | sh > /dev/null 2>&1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T18:27:14.293995Z","iopub.execute_input":"2025-07-26T18:27:14.294468Z","iopub.status.idle":"2025-07-26T18:28:06.426662Z","shell.execute_reply.started":"2025-07-26T18:27:14.294449Z","shell.execute_reply":"2025-07-26T18:28:06.425641Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import subprocess\nimport ollama\nimport os\nimport time\n\n# Set environment variable to show only errors\nenv = os.environ.copy()\nenv['OLLAMA_DEBUG'] = 'ERROR'\n\n# Start Ollama server in background\nprocess = subprocess.Popen(\n    \"ollama serve\", \n    shell=True, \n    env=env,\n    stdout=subprocess.DEVNULL,\n    stderr=subprocess.DEVNULL\n)\n\n# Give the server a moment to start\ntime.sleep(2)\n\n# Pull the model (run this in a separate process)\npull_process = subprocess.run(\n    [\"ollama\", \"pull\", \"gemma3:12b\"], \n    stdout=subprocess.DEVNULL,\n    stderr=subprocess.DEVNULL, \n    env=env\n)\n\nif pull_process.returncode == 0:\n    print(\"Model pulled successfully\")\nelse:\n    print(f\"Error pulling model: {pull_process.stderr}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T18:28:18.444004Z","iopub.execute_input":"2025-07-26T18:28:18.444301Z","iopub.status.idle":"2025-07-26T18:29:15.094625Z","shell.execute_reply.started":"2025-07-26T18:28:18.444282Z","shell.execute_reply":"2025-07-26T18:29:15.093952Z"}},"outputs":[{"name":"stdout","text":"Model pulled successfully\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"bankrupted = pd.read_csv(\"/kaggle/input/finance-project/non_bankrupted.csv\").sort_values('non_b_ticker', ascending = False)\nbankrupted['startdate'] = pd.to_datetime(bankrupted['startdate'], format = '%Y-%m-%d') + pd.offsets.DateOffset(years=-1)\nbankrupted['startdate'] = bankrupted.startdate.astype(str)\n# bankrupted = bankrupted[~bankrupted.Ticker.isin(['financials', 'financial2', 'bankrupted'])]\n\nfocused_tickers = [] \n\nfor non_b_ticker, startdate in bankrupted[['non_b_ticker', 'startdate']].sort_values('non_b_ticker').values: \n    company = Company(non_b_ticker) \n    filings = company.get_filings(form=['10-Q', '10-K']) \n    if (len(filings) >= 12):\n        focused_tickers.append(non_b_ticker) \n\nbankrupted = bankrupted[bankrupted.non_b_ticker.isin(focused_tickers)]\nbankrupted.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T18:29:33.172323Z","iopub.execute_input":"2025-07-26T18:29:33.172558Z","iopub.status.idle":"2025-07-26T18:30:10.492661Z","shell.execute_reply.started":"2025-07-26T18:29:33.172540Z","shell.execute_reply":"2025-07-26T18:30:10.491822Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"    ticker non_b_ticker                company_name   startdate     enddate\n107   FALC           ZS               Zscaler, Inc.  2018-07-06  2023-07-06\n16    SYNE          XOM     Exxon Mobil Corporation  2016-08-27  2021-08-27\n137  BIGGQ          WMT                 Walmart Inc  2019-09-09  2024-09-09\n6    YUMAQ          WMB    Williams Companies, Inc.  2015-04-16  2020-04-16\n121   BSFC          WFC  The Chefs' Warehouse, Inc.  2019-12-19  2024-12-19","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ticker</th>\n      <th>non_b_ticker</th>\n      <th>company_name</th>\n      <th>startdate</th>\n      <th>enddate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>107</th>\n      <td>FALC</td>\n      <td>ZS</td>\n      <td>Zscaler, Inc.</td>\n      <td>2018-07-06</td>\n      <td>2023-07-06</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>SYNE</td>\n      <td>XOM</td>\n      <td>Exxon Mobil Corporation</td>\n      <td>2016-08-27</td>\n      <td>2021-08-27</td>\n    </tr>\n    <tr>\n      <th>137</th>\n      <td>BIGGQ</td>\n      <td>WMT</td>\n      <td>Walmart Inc</td>\n      <td>2019-09-09</td>\n      <td>2024-09-09</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>YUMAQ</td>\n      <td>WMB</td>\n      <td>Williams Companies, Inc.</td>\n      <td>2015-04-16</td>\n      <td>2020-04-16</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>BSFC</td>\n      <td>WFC</td>\n      <td>The Chefs' Warehouse, Inc.</td>\n      <td>2019-12-19</td>\n      <td>2024-12-19</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"completed = pd.read_csv(\"/kaggle/input/finance-project/completed (2).txt\", delimiter = \"|\", header = None)\ncompleted.columns = ['ticker', 'report_date', 'shares', 'short_term_debt', 'long_term_debt', 'cash', 'notes']\ncompleted.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\nimport re\nimport json\nfrom datetime import datetime\n\nprocess = subprocess.Popen(\n    \"ollama serve\", \n    shell=True, \n    env=env,\n    stdout=subprocess.DEVNULL,\n    stderr=subprocess.DEVNULL\n)\n\ndef get_prompt(report, period_of_report, ticker): \n    return f\"\"\"\n        You are a Chartered Financial Analyst with expertise in financial statement analysis.\n        \n        Analyze the following financial report data for ticker [{ticker}] as of [{period_of_report}].\n        \n        Financial Data:\n        {report}\n        \n        Extract the following information with precision:\n        \n        1. **Outstanding Shares**: Find the total number of shares outstanding (not authorized or issued). Look for:\n           - \"Shares outstanding\"\n           - \"Common shares outstanding\" \n           - \"Weighted average shares outstanding\"\n           - Report the most recent figure\n        \n        2. **Short-term Debt**: Debt or liabilities due within 12 months for the most recent figure, including:\n           - Current portion of long-term debt\n           - Short-term borrowings\n           - Notes payable (current)\n           - Current liabilities \n        \n        3. **Long-term Debt**: Debt or liabilities due beyond 12 months for the most recent figure, including:\n           - Long-term debt (excluding current portion)\n           - Long-term notes payable\n           - Bonds payable\n           - Long-term borrowings\n           - If there is no liabilities or debt due beyond 12 month, calculate it as: Total debt (or liabilities) - Short-term debt (liabilities)\n\n        4. **Cash and Cash Equivalents**: \n            - cash\n            - liquidable assets\n        \n        CRITICAL REQUIREMENTS:\n        - Do not estimate or assume values\n        - Pay attention to scale indicators (thousands, millions, billions)\n        - APPLY the scale factor to convert all values to actual amounts\n        - If values are in thousands, multiply by 1,000\n        - If values are in millions, multiply by 1,000,000\n        - If values are in billions, multiply by 1,000,000,000\n        - Use exact numbers from the most recent period shown\n        - If using calculation method, note this in the notes field\n        - Return the final scaled values, not the original values with scale factors\n        \n        Return ONLY a JSON object in this exact format:\n        {{\n            \"ticker\": \"{ticker}\",\n            \"date\": \"{period_of_report}\",\n            \"shares\": [final_scaled_number],\n            \"short_term_debt\": [final_scaled_number],\n            \"long_term_debt\": [final_scaled_number],\n            \"cash_equivalent\": [final_scaled_number],\n            \"notes\": \"[any important notes about the data, calculation and scale applied]\"\n        }}\n    \"\"\"\n\ndef get_result(prompt, max_retries=3): \n    for attempt in range(max_retries):\n        try:\n            time.sleep(2)\n            response = ollama.chat(\n                model='gemma3:12b',\n                messages=[{'role': 'user', 'content': prompt}],\n                think=False,\n                options={\n                    'temperature': 0,\n                    'top_p': 0.1,\n                    'repeat_penalty': 1.1, \n                    'num_ctx': 128000\n                }\n            )\n            return response['message']['content']\n        except Exception as e:\n            print(f\"Attempt {attempt + 1} failed: {e}\")\n            if attempt == max_retries - 1:\n                return f\"ERROR: Failed after {max_retries} attempts: {e}\"\n            time.sleep(5)\n\ndef remove_duplicates_from_string(text):\n    \"\"\"\n    Remove duplicate lines from a string.\n    \n    Args:\n        text (str): Input text with potential duplicate lines\n    \n    Returns:\n        str: Text with duplicate lines removed\n    \"\"\"\n    lines = text.splitlines(keepends=True)\n    seen = set()\n    unique_lines = []\n    \n    for line in lines:\n        if line not in seen:\n            seen.add(line)\n            unique_lines.append(line)\n    \n    return ''.join(unique_lines)\n\ndef parse_llm_response(response_text):\n    \"\"\"Parse LLM response and extract JSON\"\"\"\n    try:\n        # Try to find JSON in the response\n        json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n        if json_match:\n            json_str = json_match.group(0)\n            return json.loads(json_str)\n        else:\n            # Fallback: try to parse the entire response\n            return json.loads(response_text)\n    except json.JSONDecodeError:\n        return {\n            \"error\": \"Failed to parse JSON response\",\n            \"raw_response\": response_text\n        }\n\ndef validate_financial_data(data):\n    \"\"\"Validate extracted financial data\"\"\"\n    required_fields = ['ticker', 'date', 'shares', 'short_term_debt', 'long_term_debt', 'cash_equivalent']\n    \n    for field in required_fields:\n        if field not in data:\n            return False, f\"Missing required field: {field}\"\n    \n    # Check if values are reasonable (not negative where they shouldn't be)\n    numeric_fields = ['shares', 'short_term_debt', 'long_term_debt', 'cash_equivalent']\n    for field in numeric_fields:\n        if isinstance(data[field], (int, float)) and data[field] < 0:\n            return False, f\"Negative value for {field}: {data[field]}\"\n    \n    return True, \"Valid\"\n\n# Main execution - following your original structure\nwith open('result.txt', 'w') as f: \n    for ticker, startdate in bankrupted[['non_b_ticker', 'startdate']].values: \n        company = Company(ticker) \n        filings = company.get_filings(form=['10-Q', '10-K']) \n        if (len(filings) >= 12): \n            try: \n                for filing in filings: \n                    extracted_text = ''\n                    obj = filing.obj()\n                    notcompleted = completed[(completed.ticker == ticker) & (completed.report_date == obj.period_of_report)].shape[0] == 0\n                    if (obj.period_of_report >= startdate) and (notcompleted): \n                        for table in obj.doc.tables(): \n                            if ('asset' in table.get_text().lower()) or ('share' in table.get_text().lower()) or ('million' in table.get_text().lower()) or ('thousand' in table.get_text().lower()): \n                                extracted_text += table.get_text()\n                        \n                        # Only process if we have relevant data\n                        if extracted_text.strip():\n                            # # Limit text length to avoid token limits\n                            # if len(extracted_text) > 8000:\n                            #     extracted_text = extracted_text[:8000] + \"\\n... [truncated]\"\n                            text = remove_duplicates_from_string(extracted_text)\n                            if len(text) > 80_000: \n                                text = text[:80_000]\n                            prompt = get_prompt(text, obj.period_of_report, ticker)\n                            result = get_result(prompt)\n                            \n                            # Parse and validate result\n                            parsed_result = parse_llm_response(result)\n                            \n                            if \"error\" not in parsed_result or \"sorry\" not in parsed_result:\n                                # Write structured output\n                                csv_line = f\"{parsed_result.get('ticker', ticker)}|{parsed_result.get('date', 'N/A')}|{parsed_result.get('shares', 'N/A')}|{parsed_result.get('short_term_debt', 'N/A')}|{parsed_result.get('long_term_debt', 'N/A')}|{parsed_result.get('cash_equivalent', 'N/A')}|\\\"{parsed_result.get('notes', '')}\\\"\"\n                                f.write(csv_line + '\\n')\n                                print(\"processed :\", ticker, obj.period_of_report)\n                            else:\n                                # Fallback to original format if parsing fails\n                                f.write(result + '\\n')\n                                print(\"error processed :\", ticker)\n                            \n                            f.flush()\n                        \n            except Exception as e:\n                print(f\"Error processing {ticker}: {e}\")\n                f.write(f\"Error processing {ticker}: {e}\\n\")\n                f.flush()\n\nprint(\"Processing complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T18:28:06.589443Z","iopub.status.idle":"2025-07-26T18:28:06.589824Z","shell.execute_reply.started":"2025-07-26T18:28:06.589633Z","shell.execute_reply":"2025-07-26T18:28:06.589649Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}